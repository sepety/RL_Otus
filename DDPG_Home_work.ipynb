{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sepety/RL_Otus/blob/main/DDPG_Home_work.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DDPG (Deep Deterministic Policy Gradient)**"
      ],
      "metadata": {
        "id": "dt9CQGHU9s5N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DDPG (Deep Deterministic Policy Gradient) ‚Äî —ç—Ç–æ –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º (RL), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å—Ä–µ–¥ —Å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º –¥–µ–π—Å—Ç–≤–∏–π. –û–Ω –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Å–µ–º–µ–π—Å—Ç–≤—É –º–µ—Ç–æ–¥–æ–≤ Actor-Critic, –≥–¥–µ —É –Ω–∞—Å –µ—Å—Ç—å –¥–≤–µ –æ—Å–Ω–æ–≤–Ω—ã–µ —Å–µ—Ç–∏:\n",
        "\n",
        "Actor (–ø–æ–ª–∏—Ç–∏–∫–∞): –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n",
        "ùúá\n",
        "(\n",
        "ùë†\n",
        "‚à£\n",
        "ùúÉ\n",
        "ùúá\n",
        ")\n",
        "Œº(s‚à£Œ∏\n",
        "Œº\n",
        "‚Äã\n",
        " ), –∫–æ—Ç–æ—Ä–∞—è –ø–æ —Å–æ—Å—Ç–æ—è–Ω–∏—é\n",
        "ùë†\n",
        "s –≤—ã–¥–∞—ë—Ç –¥–µ–π—Å—Ç–≤–∏–µ\n",
        "ùëé\n",
        "a.\n",
        "Critic (—Ü–µ–Ω–Ω–æ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è): –∞–ø–ø—Ä–æ–∫—Å–∏–º–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é Q-value,\n",
        "ùëÑ\n",
        "(\n",
        "ùë†\n",
        ",\n",
        "ùëé\n",
        "‚à£\n",
        "ùúÉ\n",
        "ùëÑ\n",
        ")\n",
        "Q(s,a‚à£Œ∏\n",
        "Q\n",
        "‚Äã\n",
        " ), –∫–æ—Ç–æ—Ä–∞—è –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏—è\n",
        "ùëé\n",
        "a –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏\n",
        "ùë†\n",
        "s.\n"
      ],
      "metadata": {
        "id": "pD6-RGwU8puu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ—Å–Ω–æ–≤—ã**"
      ],
      "metadata": {
        "id": "5zKFm5s7876H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "–¶–µ–ª–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è Critic:\n",
        "–ï—Å–ª–∏ –∞–≥–µ–Ω—Ç –∏—Å–ø–æ–ª–Ω—è–µ—Ç —Å—Ç—Ä–∞—Ç–µ–≥–∏—é\n",
        "ùúá\n",
        "Œº, –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫—Ä–∏—Ç–∏–∫–∞ –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ Q-–∑–Ω–∞—á–µ–Ω–∏—è:\n",
        "\n",
        "ùë¶\n",
        "=\n",
        "ùëü\n",
        "+\n",
        "ùõæ\n",
        "ùëÑ\n",
        "‚Ä≤\n",
        "(\n",
        "ùë†\n",
        "‚Ä≤\n",
        ",\n",
        "ùúá\n",
        "‚Ä≤\n",
        "(\n",
        "ùë†\n",
        "‚Ä≤\n",
        ")\n",
        "‚à£\n",
        "ùúÉ\n",
        "ùëÑ\n",
        "‚Ä≤\n",
        ")\n",
        ".\n",
        "y=r+Œ≥Q\n",
        "‚Ä≤\n",
        " (s\n",
        "‚Ä≤\n",
        " ,Œº\n",
        "‚Ä≤\n",
        " (s\n",
        "‚Ä≤\n",
        " )‚à£Œ∏\n",
        "Q\n",
        "‚Ä≤\n",
        "\n",
        "‚Äã\n",
        " ).\n",
        "–ó–¥–µ—Å—å:\n",
        "\n",
        "ùëü\n",
        "r ‚Äî –Ω–∞–≥—Ä–∞–¥–∞ –∑–∞ —Ç–µ–∫—É—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ\n",
        "ùõæ\n",
        "Œ≥ ‚Äî –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–±—ã—á–Ω–æ\n",
        "ùõæ\n",
        "‚àà\n",
        "[\n",
        "0.9\n",
        ",\n",
        "0.99\n",
        "]\n",
        "Œ≥‚àà[0.9,0.99])\n",
        "ùëÑ\n",
        "‚Ä≤\n",
        "Q\n",
        "‚Ä≤\n",
        "  –∏\n",
        "ùúá\n",
        "‚Ä≤\n",
        "Œº\n",
        "‚Ä≤\n",
        "  ‚Äî —Ü–µ–ª–µ–≤—ã–µ —Å–µ—Ç–∏ –∫—Ä–∏—Ç–∏–∫–∞ –∏ –∞–∫—Ç—ë—Ä–∞, —Å–ª—É–∂–∞—â–∏–µ –¥–ª—è —Å—Ç–∞–±–∏–ª–∏–∑–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω–∏—è.\n",
        "–ö—Ä–∏—Ç–∏–∫ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø—É—Ç—ë–º –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –æ—à–∏–±–∫–∏ –ú–°–ï –º–µ–∂–¥—É –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º\n",
        "ùëÑ\n",
        "(\n",
        "ùë†\n",
        ",\n",
        "ùëé\n",
        ")\n",
        "Q(s,a) –∏ —Ü–µ–ª–µ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º\n",
        "ùë¶\n",
        "y.\n",
        "\n",
        "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Actor:\n",
        "Actor –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º –ø–æ–ª–∏—Ç–∏–∫–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞:\n",
        "\n",
        "‚àá\n",
        "ùúÉ\n",
        "ùúá\n",
        "ùêΩ\n",
        "‚âà\n",
        "ùê∏\n",
        "[\n",
        "‚àá\n",
        "ùëé\n",
        "ùëÑ\n",
        "(\n",
        "ùë†\n",
        ",\n",
        "ùëé\n",
        "‚à£\n",
        "ùúÉ\n",
        "ùëÑ\n",
        ")\n",
        "‚àá\n",
        "ùúÉ\n",
        "ùúá\n",
        "ùúá\n",
        "(\n",
        "ùë†\n",
        "‚à£\n",
        "ùúÉ\n",
        "ùúá\n",
        ")\n",
        "]\n",
        ",\n",
        "‚àá\n",
        "Œ∏\n",
        "Œº\n",
        "‚Äã\n",
        "\n",
        "‚Äã\n",
        " J‚âàE[‚àá\n",
        "a\n",
        "‚Äã\n",
        " Q(s,a‚à£Œ∏\n",
        "Q\n",
        "‚Äã\n",
        " )‚àá\n",
        "Œ∏\n",
        "Œº\n",
        "‚Äã\n",
        "\n",
        "‚Äã\n",
        " Œº(s‚à£Œ∏\n",
        "Œº\n",
        "‚Äã\n",
        " )],\n",
        "—á—Ç–æ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ –æ–∑–Ω–∞—á–∞–µ—Ç —É–ª—É—á—à–µ–Ω–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ —Ç–∞–∫, —á—Ç–æ–±—ã —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å Q-–∑–Ω–∞—á–µ–Ω–∏—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π."
      ],
      "metadata": {
        "id": "AE9qPiA58wU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫**"
      ],
      "metadata": {
        "id": "gnxvalnS97_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "—É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫: gymnasium —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π box2d –¥–ª—è —Å—Ä–µ–¥—ã CarRacing, –∞ —Ç–∞–∫–∂–µ matplotlib, torch, torchvision –∏ opencv-python –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."
      ],
      "metadata": {
        "id": "jdSXGgAk-A5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium[box2d]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1SCBSNUMJ_m",
        "outputId": "d4446b52-f149-4e52-d4a9-9977b0ed7d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium[box2d]\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium[box2d])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Collecting box2d-py==2.3.5 (from gymnasium[box2d])\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.6.1)\n",
            "Collecting swig==4.* (from gymnasium[box2d])\n",
            "  Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.3.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Downloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m√ó\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRjKs0dCCYFX",
        "outputId": "98dbd3e0-33de-4854-d1d4-ce40f2ce9c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install matplotlib torch torchvision opencv-python\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏.\n",
        "–°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É CarRacing-v3 —Å –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º –¥–µ–π—Å—Ç–≤–∏–π.\n",
        "–°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ä–µ–¥—É –∏ –≤—ã–≤–æ–¥–∏–º —Ä–∞–∑–º–µ—Ä—ã –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤ —Å–æ—Å—Ç–æ—è–Ω–∏–π –∏ –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏.\n",
        "–ó–∞–∫—Ä—ã–≤–∞–µ–º —Å—Ä–µ–¥—É –ø–æ—Å–ª–µ –ø—Ä–æ–≤–µ—Ä–∫–∏."
      ],
      "metadata": {
        "id": "Tw3jNstK-TO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2  # –î–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–±–æ—Ç—É —Å—Ä–µ–¥—ã\n",
        "env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", continuous=True)\n",
        "obs, info = env.reset()\n",
        "print(\"Observation Space:\", env.observation_space)\n",
        "print(\"Action Space:\", env.action_space)\n",
        "env.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_0WuDEJHNUa",
        "outputId": "4ea78ab4-277a-4845-b093-be027b04c791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation Space: Box(0, 255, (96, 96, 3), uint8)\n",
            "Action Space: Box([-1.  0.  0.], 1.0, (3,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ü–æ–≤—Ç–æ—Ä–Ω–æ —Å–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É CarRacing-v3.\n",
        "–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ –æ–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω–æ–µ (–≥—Ä–∞–¥–∞—Ü–∏–∏ —Å–µ—Ä–æ–≥–æ) –∏ —É–º–µ–Ω—å—à–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –¥–æ 64x64.\n",
        "–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏—è (–æ–±—ã—á–Ω–æ 3: –ø–æ–≤–æ—Ä–æ—Ç, –≥–∞–∑, —Ç–æ—Ä–º–æ–∑) –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ (1.0).\n",
        "–í—ã–≤–æ–¥–∏–º —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏.\n"
      ],
      "metadata": {
        "id": "Ak2F2MvP-dDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from collections import deque\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É\n",
        "env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", continuous=True)\n",
        "\n",
        "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º—É —Å–æ—Å—Ç–æ—è–Ω–∏—è –ø–æ—Å–ª–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏\n",
        "state_shape = (1, 64, 64)  # –û–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ 64x64\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –¥–µ–π—Å—Ç–≤–∏–π –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –∏–∑ —Å—Ä–µ–¥—ã\n",
        "action_dim = env.action_space.shape[0]\n",
        "max_action = env.action_space.high[0]\n",
        "\n",
        "print(f\"State Shape: {state_shape}\")\n",
        "print(f\"Action Dimension: {action_dim}\")\n",
        "print(f\"Max Action: {max_action}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfS0sDiLMvfO",
        "outputId": "492ed59d-52d3-401e-c404-cf2334b01821"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Shape: (1, 64, 64)\n",
            "Action Dimension: 3\n",
            "Max Action: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –ø–∞–∫–µ—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Å–±–æ—Ä–∫–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π. –û–±—ã—á–Ω–æ –≤ Colab –∏–ª–∏ –ø–æ–¥–æ–±–Ω—ã—Ö —Å—Ä–µ–¥–∞—Ö —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–π –º–∞—à–∏–Ω–µ –º–æ–∂–µ—Ç –ø—Ä–∏–≥–æ–¥–∏—Ç—å—Å—è."
      ],
      "metadata": {
        "id": "Hl5CS3jt-l_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n"
      ],
      "metadata": {
        "id": "VRR7220nX70X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y swig build-essential cmake\n",
        "!pip install swig\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McloVCcSL_42",
        "outputId": "f2a3ca85-f114-4f5d-b848-cdd2815c9274"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "The following additional packages will be installed:\n",
            "  swig4.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig4.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,116 kB of archives.\n",
            "After this operation, 5,542 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Fetched 1,116 kB in 1s (754 kB/s)\n",
            "Selecting previously unselected package swig4.0.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting swig\n",
            "  Downloading swig-4.2.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (3.5 kB)\n",
            "Downloading swig-4.2.1.post0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.2.1.post0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "–≠—Ç–æ –∫–ª–∞—Å—Å –±—É—Ñ–µ—Ä–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ö—Ä–∞–Ω–∏—Ç—Å—è –æ–ø—ã—Ç –∞–≥–µ–Ω—Ç–∞. –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º—ã –±—É–¥–µ–º –±—Ä–∞—Ç—å –∏–∑ –Ω–µ–≥–æ —Å–ª—É—á–∞–π–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –∏ —É–ª—É—á—à–∏—Ç—å —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è."
      ],
      "metadata": {
        "id": "K9co7L1n-1pT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, capacity):\n",
        "        self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "    def add(self, state, action, reward, next_state, done):\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        states, actions, rewards, next_states, dones = zip(*batch)\n",
        "        actions = np.array(actions)\n",
        "        rewards = np.array(rewards)\n",
        "        dones = np.array(dones)\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n"
      ],
      "metadata": {
        "id": "ZWBVdpkcNAR2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–§—É–Ω–∫—Ü–∏—è —É–º–µ–Ω—å—à–∞–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞, –¥–µ–ª–∞–µ—Ç –µ–≥–æ –æ–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω—ã–º –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç. –≠—Ç–æ —É–º–µ–Ω—å—à–∞–µ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—É—é –Ω–∞–≥—Ä—É–∑–∫—É –∏ —É–ø—Ä–æ—â–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
      ],
      "metadata": {
        "id": "A-vzorCt-8E6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_state(state):\n",
        "    \"\"\"\n",
        "    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –≤ –æ—Ç—Ç–µ–Ω–∫–∞—Ö —Å–µ—Ä–æ–≥–æ.\n",
        "    \"\"\"\n",
        "    state = cv2.resize(state, (64, 64))  # –ò–∑–º–µ–Ω–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "    state = cv2.cvtColor(state, cv2.COLOR_RGB2GRAY)  # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –æ—Ç—Ç–µ–Ω–∫–∏ —Å–µ—Ä–æ–≥–æ\n",
        "    state = state / 255.0  # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
        "    state = np.expand_dims(state, axis=0)  # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–Ω–∞–ª (1, 64, 64)\n",
        "    return torch.tensor(state, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "jm1jJVYDWLoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ê–∫—Ç–æ—Ä–Ω–∞—è —Å–µ—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –∏–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ–π—Å—Ç–≤–∏–µ –≤ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–≤—ë—Ä—Ç–æ–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–µ—Ç–∏ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω–æ —É—á–∏—Ç—å –≤–∞–∂–Ω—ã–µ –≤–∏–∑—É–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏."
      ],
      "metadata": {
        "id": "GZPwjZHu-9IW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ö—Ä–∏—Ç–∏–∫ –æ—Ü–µ–Ω–∏–≤–∞—Ç –∫–∞—á–µ—Å—Ç–≤–æ –¥–µ–π—Å—Ç–≤–∏—è –≤ –¥–∞–Ω–Ω–æ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏, –≤—ã–¥–∞–≤–∞—è Q-–∑–Ω–∞—á–µ–Ω–∏–µ. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∞–∫—Ç–æ—Ä—É —É–ª—É—á—à–∞—Ç—å —Å–≤–æ—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é."
      ],
      "metadata": {
        "id": "alUFnGxq_PRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_shape, action_dim, max_action):\n",
        "        super(Actor, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞ –ø–æ—Å–ª–µ —Å–≤—ë—Ä—Ç–æ–∫\n",
        "        self._init_conv_output(state_shape)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.conv_output_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, action_dim)\n",
        "        self.max_action = max_action\n",
        "\n",
        "    def _init_conv_output(self, shape):\n",
        "        with torch.no_grad():\n",
        "            input = torch.zeros(1, *shape)\n",
        "            x = F.relu(self.conv1(input))\n",
        "            x = F.relu(self.conv2(x))\n",
        "            self.conv_output_dim = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = F.relu(self.conv1(state))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, self.conv_output_dim)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = torch.tanh(self.fc2(x)) * self.max_action\n",
        "        return x\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_shape, action_dim):\n",
        "        super(Critic, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=8, stride=4)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "\n",
        "        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–∞ –ø–æ—Å–ª–µ —Å–≤—ë—Ä—Ç–æ–∫\n",
        "        self._init_conv_output(state_shape)\n",
        "\n",
        "        self.fc1 = nn.Linear(self.conv_output_dim + action_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 1)\n",
        "\n",
        "    def _init_conv_output(self, shape):\n",
        "        with torch.no_grad():\n",
        "            input = torch.zeros(1, *shape)\n",
        "            x = F.relu(self.conv1(input))\n",
        "            x = F.relu(self.conv2(x))\n",
        "            self.conv_output_dim = x.view(1, -1).shape[1]\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        x = F.relu(self.conv1(state))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(-1, self.conv_output_dim)\n",
        "        x = torch.cat([x, action], dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "RdYWuaqJWRgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–ê–≥–µ–Ω—Ç —Ä–µ–∞–ª–∏–∑—É–µ—Ç DDPG. –û–Ω –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±—É—Ñ–µ—Ä, —Ü–µ–ª–µ–≤—ã–µ —Å–µ—Ç–∏ –∏ –º—è–≥–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ. –ï—Å—Ç—å –º–µ—Ç–æ–¥—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π."
      ],
      "metadata": {
        "id": "6i3GJMlh_as5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPGAgent:\n",
        "    def __init__(self, state_shape, action_dim, max_action):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.action_dim = action_dim\n",
        "        self.max_action = max_action\n",
        "\n",
        "        self.actor = Actor(state_shape, action_dim, max_action).to(self.device)\n",
        "        self.actor_target = Actor(state_shape, action_dim, max_action).to(self.device)\n",
        "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=1e-4)\n",
        "\n",
        "        self.critic = Critic(state_shape, action_dim).to(self.device)\n",
        "        self.critic_target = Critic(state_shape, action_dim).to(self.device)\n",
        "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=1e-3)\n",
        "\n",
        "        self.replay_buffer = ReplayBuffer(100000)\n",
        "        self.gamma = 0.99\n",
        "        self.tau = 0.005\n",
        "\n",
        "        self.best_avg_reward = -np.inf\n",
        "\n",
        "    def select_action(self, state):\n",
        "        state = preprocess_state(state).unsqueeze(0).to(self.device)  # –î–æ–±–∞–≤–ª—è–µ–º batch —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å\n",
        "        self.actor.eval()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
        "        with torch.no_grad():\n",
        "            action = self.actor(state).cpu().numpy()[0]\n",
        "        self.actor.train()  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
        "        # –î–æ–±–∞–≤–ª—è–µ–º —à—É–º –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è\n",
        "        noise = np.random.normal(0, self.max_action * 0.1, size=self.action_dim)\n",
        "        action = action + noise\n",
        "        action = np.clip(action, -self.max_action, self.max_action)\n",
        "        return action\n",
        "\n",
        "    def train(self, batch_size):\n",
        "        if len(self.replay_buffer) < batch_size:\n",
        "            return\n",
        "\n",
        "        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞—Ç—á –∏–∑ —Ä–µ–ø–ª–µ–π –±—É—Ñ–µ—Ä–∞\n",
        "        states, actions, rewards, next_states, dones = self.replay_buffer.sample(batch_size)\n",
        "\n",
        "        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å–ø–∏—Å–∫–∏ —Ç–µ–Ω–∑–æ—Ä–æ–≤ –≤ —Ç–µ–Ω–∑–æ—Ä—ã –±–∞—Ç—á–∞\n",
        "        states = torch.stack(states).to(self.device)\n",
        "        next_states = torch.stack(next_states).to(self.device)\n",
        "        actions = torch.tensor(actions, dtype=torch.float32).to(self.device)\n",
        "        rewards = torch.tensor(rewards, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "        dones = torch.tensor(dones, dtype=torch.float32).unsqueeze(1).to(self.device)\n",
        "\n",
        "        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Critic\n",
        "        with torch.no_grad():\n",
        "            next_actions = self.actor_target(next_states)\n",
        "            target_Q = self.critic_target(next_states, next_actions)\n",
        "            target_Q = rewards + (1 - dones) * self.gamma * target_Q\n",
        "\n",
        "        current_Q = self.critic(states, actions)\n",
        "        critic_loss = nn.MSELoss()(current_Q, target_Q)\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ Actor\n",
        "        actor_loss = -self.critic(states, self.actor(states)).mean()\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "\n",
        "        # –ú—è–≥–∫–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤—ã—Ö —Å–µ—Ç–µ–π\n",
        "        self.soft_update(self.actor_target, self.actor)\n",
        "        self.soft_update(self.critic_target, self.critic)\n",
        "\n",
        "    def soft_update(self, target_net, source_net):\n",
        "        for target_param, param in zip(target_net.parameters(), source_net.parameters()):\n",
        "            target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
        "\n",
        "    def save_models(self, episode):\n",
        "        torch.save(self.actor.state_dict(), os.path.join(model_dir, f'ddpg_actor_episode_{episode}.pth'))\n",
        "        torch.save(self.critic.state_dict(), os.path.join(model_dir, f'ddpg_critic_episode_{episode}.pth'))\n",
        "        print(f\"Models saved at episode {episode}\")\n",
        "\n",
        "    def load_models(self, actor_path, critic_path):\n",
        "        self.actor.load_state_dict(torch.load(os.path.join(model_dir, actor_path)))\n",
        "        self.critic.load_state_dict(torch.load(os.path.join(model_dir, critic_path)))\n",
        "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "        print(\"Models loaded successfully\")\n",
        "\n",
        "    def save_models(self, episode):\n",
        "        torch.save({\n",
        "        'actor_state_dict': self.actor.state_dict(),\n",
        "        'critic_state_dict': self.critic.state_dict(),\n",
        "        'actor_optimizer_state_dict': self.actor_optimizer.state_dict(),\n",
        "        'critic_optimizer_state_dict': self.critic_optimizer.state_dict(),\n",
        "        }, os.path.join(model_dir, f'ddpg_checkpoint_episode_{episode}.pth'))\n",
        "        print(f\"Models and optimizers saved at episode {episode}\")\n",
        "    def load_models(self, checkpoint_path):\n",
        "        checkpoint = torch.load(os.path.join(model_dir, checkpoint_path))\n",
        "        self.actor.load_state_dict(checkpoint['actor_state_dict'])\n",
        "        self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
        "        self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer_state_dict'])\n",
        "        self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer_state_dict'])\n",
        "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "        print(\"Models and optimizers loaded successfully\")\n",
        "\n"
      ],
      "metadata": {
        "id": "q9EdfgutWUOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "model_dir = '/content/drive/MyDrive/DDPG AGENT'\n",
        "os.makedirs(model_dir, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "V8zeRsnPW3t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "–°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π. –ï—Å–ª–∏ –≤—ã —Ä–∞–±–æ—Ç–∞–µ—Ç–µ –≤ Google Colab –∏ –ø–æ–¥–∫–ª—é—á–∏–ª–∏ Google Drive, —ç—Ç–æ —Å–æ–∑–¥–∞—Å—Ç –ø–∞–ø–∫—É –≤ –≤–∞—à–µ–º –æ–±–ª–∞—á–Ω–æ–º —Ö—Ä–∞–Ω–∏–ª–∏—â–µ.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y92VpYqGVK6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pjkKHA1jVKzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "–í—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è –Ω–∞ 500 —ç–ø–∏–∑–æ–¥–æ–≤.\n",
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ø–∏–∑–æ–¥–∞ –∞–≥–µ–Ω—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤—É–µ—Ç —Å–æ —Å—Ä–µ–¥–æ–π, —Å–æ–±–∏—Ä–∞–µ—Ç –Ω–∞–≥—Ä–∞–¥—ã –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥—ã –≤ –±—É—Ñ–µ—Ä.\n",
        "–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–∫—Ç—ë—Ä–∞ –∏ –∫—Ä–∏—Ç–∏–∫–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –Ω–∞–±–æ—Ä–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ—Ö–æ–¥–æ–≤.\n",
        "–ö–∞–∂–¥—ã–µ 5 —ç–ø–∏–∑–æ–¥–æ–≤ –ø–µ—á–∞—Ç–∞–µ—Ç—Å—è —Å—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞, —á—Ç–æ–±—ã –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è."
      ],
      "metadata": {
        "id": "BOBs57pXVKvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞\n",
        "agent = DDPGAgent(state_shape, action_dim, max_action)\n",
        "episodes = 500  # –ú–æ–∂–Ω–æ —É–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
        "batch_size = 16\n",
        "episode_rewards = []\n",
        "\n",
        "for episode in range(episodes):\n",
        "    state, _ = env.reset()\n",
        "    episode_reward = 0\n",
        "    done = False\n",
        "    steps = 0  # –°—á–µ—Ç—á–∏–∫ —à–∞–≥–æ–≤ –≤ —ç–ø–∏–∑–æ–¥–µ\n",
        "\n",
        "    while not done:\n",
        "        action = agent.select_action(state)\n",
        "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        # –ü—Ä–µ–¥–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏—è\n",
        "        state_processed = preprocess_state(state)\n",
        "        next_state_processed = preprocess_state(next_state)\n",
        "\n",
        "        agent.replay_buffer.add(state_processed, action, reward, next_state_processed, done)\n",
        "        agent.train(batch_size)\n",
        "\n",
        "        state = next_state\n",
        "        episode_reward += reward\n",
        "        steps += 1\n",
        "\n",
        "        if steps >= 1000:\n",
        "            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –≤ —ç–ø–∏–∑–æ–¥–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
        "            break\n",
        "\n",
        "    episode_rewards.append(episode_reward)\n",
        "\n",
        "    if (episode + 1) % 5 == 0:\n",
        "        avg_reward = np.mean(episode_rewards[-5:])\n",
        "        print(f\"Episode {episode + 1}, Average Reward: {avg_reward:.2f}\")\n",
        "\n",
        "env.close()\n",
        "\n",
        "\n",
        "# –ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞\n",
        "plt.plot(episode_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Training Reward per Episode')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90Op3ZFBWbzF",
        "outputId": "3a88c352-a1b9-4068-d17e-dd6aa8f2ffb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 5, Average Reward: -81.57\n",
            "Episode 10, Average Reward: -77.91\n",
            "Episode 15, Average Reward: -82.39\n",
            "Episode 20, Average Reward: -81.82\n",
            "Episode 25, Average Reward: -64.67\n",
            "Episode 30, Average Reward: -57.68\n",
            "Episode 35, Average Reward: -61.23\n",
            "Episode 40, Average Reward: -58.13\n",
            "Episode 45, Average Reward: -27.66\n",
            "Episode 50, Average Reward: -36.34\n",
            "Episode 55, Average Reward: -58.34\n",
            "Episode 60, Average Reward: -33.99\n",
            "Episode 65, Average Reward: -44.32\n",
            "Episode 70, Average Reward: -15.60\n",
            "Episode 75, Average Reward: -37.79\n",
            "Episode 80, Average Reward: -8.40\n",
            "Episode 85, Average Reward: -5.61\n",
            "Episode 90, Average Reward: -44.17\n",
            "Episode 95, Average Reward: -27.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞–≥—Ä–∞–¥—ã –ø–æ —ç–ø–∏–∑–æ–¥–∞–º\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(episode_rewards, label='Episode Reward')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.title('Training Reward per Episode')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "O_dLliECL62F",
        "outputId": "f8dbc05e-3955-4e1c-a60c-2d98e0577694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8ea21dbaca9e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–∞–≥—Ä–∞–¥—ã –ø–æ —ç–ø–∏–∑–æ–¥–∞–º\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Episode Reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Episode'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio_ffmpeg\n",
        "!pip install imageio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_o9-AaAMCb5",
        "outputId": "322b4b13-f508-45fe-9365-fc8dde86fa99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (75.1.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.36.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from gymnasium.wrappers import RecordVideo\n",
        "\n",
        "# –£–∫–∞–∑—ã–≤–∞–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ\n",
        "video_folder = 'videos'\n",
        "os.makedirs(video_folder, exist_ok=True)\n",
        "\n",
        "# –°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É —Å –æ–±—ë—Ä—Ç–∫–æ–π RecordVideo\n",
        "env = gym.make(\"CarRacing-v3\", render_mode=\"rgb_array\", continuous=True)\n",
        "env = RecordVideo(env, video_folder=video_folder, episode_trigger=lambda episode_id: True)\n",
        "\n",
        "state, _ = env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "agent.actor.eval()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
        "\n",
        "while not done:\n",
        "    state_processed = preprocess_state(state).unsqueeze(0).to(agent.device)\n",
        "    with torch.no_grad():\n",
        "        action = agent.actor(state_processed).cpu().numpy()[0]\n",
        "    state, reward, terminated, truncated, _ = env.step(action)\n",
        "    done = terminated or truncated\n",
        "    total_reward += reward\n",
        "\n",
        "env.close()\n",
        "print(f\"Total Reward: {total_reward}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhO1hOtFMF-5",
        "outputId": "b6eb857d-4879-42ef-c114-62e213ea6f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /content/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Reward: -85.13011152416297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ –≤–Ω—É—Ç—Ä–∏ –Ω–æ—É—Ç–±—É–∫–∞\n",
        "def show_video(video_path):\n",
        "    video = io.open(video_path, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    HTML(data='''\n",
        "        <video width=\"640\" height=\"480\" controls>\n",
        "            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "        </video>\n",
        "    '''.format(encoded.decode('ascii')))\n",
        "\n",
        "# –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ\n",
        "import glob\n",
        "list_of_videos = glob.glob(os.path.join(video_folder, '*.mp4'))\n",
        "latest_video = max(list_of_videos, key=os.path.getctime)\n",
        "\n",
        "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤–∏–¥–µ–æ\n",
        "show_video(latest_video)\n"
      ],
      "metadata": {
        "id": "VIQMP2slMWzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_episodes = 3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–∏–∑–æ–¥–æ–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "    state, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    agent.actor.eval()  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏\n",
        "\n",
        "    while not done:\n",
        "        state_processed = preprocess_state(state).unsqueeze(0).to(agent.device)\n",
        "        with torch.no_grad():\n",
        "            action = agent.actor(state_processed).cpu().numpy()[0]\n",
        "        state, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "\n",
        "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpYJHnYkMfHV",
        "outputId": "33d5f28c-cc5d-4e9d-e5b9-f3aa8d3979f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 1, Total Reward: -83.27759197324364\n",
            "Episode 2, Total Reward: -83.05084745762663\n",
            "Episode 3, Total Reward: -83.27759197324364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# –í—ã–≤–æ–¥–∏–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –≤–∏–¥–µ–æ\n",
        "for idx, video_path in enumerate(list_of_videos):\n",
        "    print(f\"{idx + 1}: {video_path}\")\n",
        "\n",
        "# –í–≤–æ–¥–∏–º –Ω–æ–º–µ—Ä –≤–∏–¥–µ–æ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è\n",
        "video_number = int(input(\"Enter the number of the video to display: \")) - 1\n",
        "selected_video = list_of_videos[video_number]\n",
        "\n",
        "# –û—Ç–æ–±—Ä–∞–∂–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω–æ–µ –≤–∏–¥–µ–æ\n",
        "show_video(selected_video)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZW6mUDKMj_q",
        "outputId": "ab547359-117b-4fdc-9f16-3452a46e27f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1: videos/rl-video-episode-0.mp4\n",
            "Enter the number of the video to display: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T54zLzHMMFIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-BcH2U2nMFFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lh2cE5gYMFA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "eLaTyvRY8DUB",
        "outputId": "a50c1533-c8ac-4e42-fb42-d7099f718603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2eaca526b1e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9v71CWWUWUBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bWV2Y48SWT-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4bvZNHhkWT7q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zp7LUqHbWT3f"
      }
    }
  ]
}